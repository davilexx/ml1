# kNN

kNN расшифровывается как k Nearest Neighbor или k Ближайших Соседей — это один из самых простых алгоритмов классификации, также иногда используемый в задачах регрессии. Благодаря своей простоте, он является хорошим примером, с которого можно начать знакомство с областью Machine Learning.

<b>Алгоритм</b>

Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:

<ul>
  <li>Вычислить расстояние до каждого из объектов обучающей выборки</li>
  <li>Отобрать k объектов обучающей выборки, расстояние до которых минимально</li>
  <li>Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди k ближайших соседей</li>
</ul>

 <img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/03/knn3.png" width="550" height="500" style="text-align: center"> 
 
<p style="text-align: center">Пример классификации k {\displaystyle k} k-ближайших соседей. Тестовый образец (зелёный круг) должен быть классифицирован как синий квадрат (класс 1) или как красный треугольник (класс 2). Если k = 3, то он классифицируется как 2-й класс, потому что внутри меньшего круга 2 треугольника и только 1 квадрат. Если k = 5, то он будет классифицирован как 1-й класс (3 квадрата против 2 треугольников внутри большего круга)</p>
